# Kafka



## Event Streaming

카프카 공식 홈페이지에서 카프카를 소개하기 전에 이벤트 스트리밍에 대해 언급한다.

>기술적으로, 이벤트 스트리밍은 Database, 센서, 모바일 장치, 클라우드 서비스, 애플리케이션과 같은 event source에서 이벤트 스틑림 형태로 실시간으로 데이터를 캡쳐하고, 그 이벤트 스트림을 검색하기 위해 저장하고, 조작하고, 처리하고, 이벤트 스트림에 대해 실시간으로 반응하고, 다른 대상 기술로 이벤트 스트림을 라우팅하는 것들을 말한다. 이벤트 스트리밍은 데이터의 연속적인 흐름과 해석을 보장하며 올바른 정보가 적절한 시간에 올바른 위치에 있도록 한다.



이벤트 스트리밍은 매우 다양한 경우에 사용하고 있다. 예를 들면 아래와 같은 경우에 사용한다.

* 실시간 결제 및 금융 거래를 처리할 때
* 자동차, 트럭과 같은 운송수단에 대해 실시간으로 추적하고 모니터링 할 때
* 센서 데이터를 지속적으로 캡쳐하고 분석할 때
* 고객과의 상호작용에 대해 수집하고 즉시 반응할 때 등등..



### Kafka는 이벤트 스트리밍 플랫폼!

Kafka는 세 가지의 주요 기능을 가지고 있다.

* 이벤트 스트림을 발행하고 구독한다.
* 지속적이고 안정적으로 이벤트 스트림을 저장한다.
* 이벤트 스트림을 발생시키거나 처리한다.



위에서 언급된 모든 기능은 확장성이 뛰어나고 유연하며 내결함성이 뛰어나고 안전한 방식으로 제공된다. Kafka는 일반 하드웨어, 가상머신, 컨테이너나 클라우드 환경 등 거의 모든 환경에서 배포할 수 있다. 



### Kakfa는 어떻게 돌아가는가?

kafka는 TCP로 통신하는 서버와 클라이언트로 구성된 분산 시스템이다. 

* **Server**: Kafka는 여러 데이터센터나 클라우드 영역에 걸쳐 하나 이상의 서버 클러스트로 돌아간다. 이 서버들 중 일부는 **broker** 라고 불리는 storage layer 형태를 갖추고, 나머지 다른 서버들은 Kafka connect를 실행하여 데이터를 지속적으로 이벤트 스트림으로 가져오고 내보내 RDB나 다른 kafka 클러스터와 같은 기존 시스템과 통합한다. Kafka 클러스터는 확장성과 내결함성이 뛰어난다. 예를 들어, 클러스터 내 어떤 서버가 죽어도 다른 서버가 살아있기 때문에 데이터 손실 없이 지속적으로 kafka 서버를 유지할 수 있다.
* **client**: 네트워크 장애나 기계 결함이 발생하더라도 이벤트 스트림을 병렬로 읽고, 쓰고, 처리하는 분산 애플리케이션과 마이크로서비스를 작성할 수 있다.



### Kafka의 주요 개념과 기술

이벤트는 비즈니스 환경에서 "어떤 일이 일어났다" 라는 것을 기록한다. 이벤트는 공식 문서에서 record나 message로 불리기도 한다. 데이터를 kafka를 통해 읽거나 쓸 때는 이벤트 형태로 이루어진다. 개념적으로 이벤트는 key, value, timestamp와 optional metadata header를 가진다. 



**Producer**는 kafka 이벤트를 발행하는 클라이언트 에플리케이션이고, **Consumer**는 그 이벤트를 구독하는 애플리케이션이다. Kafka에서는 producer와 consumer는 완전히 분리되어있으며, 그들이 각각 누군지 모른다. 이러한 특징 때문에 Kafka는 확장성이 매우 뛰어나다. 그리고 kafka는 이벤트를 정확히 한 번 처리하는 능력과 같은 다양한 것을 제공한다.



이벤트는 조직적이고 topic에 저장된다. Topic은 파일 시스템의 폴더와 비슷하며, 이벤트는 폴더에서의 파일의 역할을 하고 잇다고 보면 된다. Kafka의 Topic은 항상 multi-producer와 multi-subscriber이다. 그리고 Topic의 이벤트는 필요한 만큼 자주 읽을 수 있다. 전통적인 메세징 시스템과 달리, 이벤트는 소비한 후 지워지지 않는다. 대신, 한 topice당 이벤트를 얼마나 오래 유지해야 하는지 정의하고 오래 저장된 이벤트는 삭제되도록 설정해야 한다. (용량 문제) Kafka의 성능은 데이터 크기와 관련하여 일정하기 때문에(?) 장기간 저장해도 괜찮다. (데이터 갯수와 상관없이 상수?)



Topic이 분할된다는 것은 topic이 서로 다른 kafka broker에 위치한 여러 버킷에 분산되어 있다는 의미이다. 데이터의 분산 배치는 확장성 측면에서 매우 중요하다. 데이터가 분산 배치되어 있으면 클라이언트가 동시에 많은 브로커로부터 데이터를 읽고 쓸 수 있도록 하기 때문이다. 새로운 이벤트가 topic에 발행되면, topic의 파티션 중 하나에 쌓이게 된다. 이벤트 키가 같은 이벤트는 같은 파티션에 작성된다. 그리고 kafka는 주어진 topic-partition의 컨슈머가 항상 그 파티션의 이벤트를 작성된 것과 정확히 같은 순서로 읽을 수 있도록 보장한다. 



데이터의 내결함성 및 고가용성을 높이기 위해 모든 topic은 복제될 수 있다. 장애가 날 경우를 대비해서 항상 같은 데이터를 가지고 있는 브로커들이 항상 존재해 내결함성을 유지할 수 있다. 그래서 여러 개의 브로커를 유지해야 한다. 보통, 일반적인 프로덕션 레벨에서는 3개 이상의 레플리카가 필요하다









































